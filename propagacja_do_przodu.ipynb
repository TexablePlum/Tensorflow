{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e066a64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.52, 0.42]), 'bias': array([0.05])}, 'node_2': {'weights': array([0.57, 0.8 ]), 'bias': array([0.11])}}, 'layer_2': {'node_1': {'weights': array([0.28, 0.64]), 'bias': array([0.49])}, 'node_2': {'weights': array([0.51, 0.46]), 'bias': array([0.89])}}, 'output': {'node_1': {'weights': array([0.61, 0.6 ]), 'bias': array([0.44])}}}\n",
      "Wejścia do sieci to [0.15 0.74 0.26 0.53 0.01]\n",
      "Suma ważona dla pierwszego neuronu w warstwie ukrytej wynosi 1.8841\n",
      "Wynik aktywacji pierwszego neuronu w warstwie ukrytej wynosi 0.8681\n",
      "Wyjścia neuronów w warstwie ukrytej numer 1 to [np.float64(0.8681), np.float64(0.8295), np.float64(0.803)]\n",
      "Wyjścia neuronów w warstwie ukrytej numer 2 to [np.float64(0.9425), np.float64(0.9039)]\n",
      "Wyjścia neuronów w warstwie ukrytej numer 3 to [np.float64(0.7267), np.float64(0.8477), np.float64(0.7605)]\n",
      "Sieć przewiduje wartość 0.7961\n",
      "Wyjścia neuronów w warstwie ukrytej numer 1 to [np.float64(0.8857), np.float64(0.8889)]\n",
      "Wyjścia neuronów w warstwie ukrytej numer 2 to [np.float64(0.7822), np.float64(0.6965), np.float64(0.7411)]\n",
      "Wyjścia neuronów w warstwie ukrytej numer 3 to [np.float64(0.868), np.float64(0.881)]\n",
      "Sieć przewiduje wartości [np.float64(0.8952), np.float64(0.8222), np.float64(0.8035)]\n"
     ]
    }
   ],
   "source": [
    "# Budowa sieci neuronowej\n",
    "\n",
    "import numpy as np\n",
    "from random import seed\n",
    "\n",
    "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    \"\"\"\n",
    "    Funkcja inicjalizująca sieć z zadanymi parametrami.\n",
    "    \"\"\"\n",
    "    num_nodes_previous = num_inputs  # liczba neuronów w poprzedniej warstwie\n",
    "\n",
    "    network = {}  # pusta sieć\n",
    "\n",
    "    # iteracja przez wszystkie warstwy i losowa inicjalizacja wag oraz biasów\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output'  # ostatnia warstwa stanowi warstwę wyjściową\n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1)  # dla pozostałych warstw przypisujemy numer\n",
    "            num_nodes = num_nodes_hidden[layer]\n",
    "        \n",
    "        # inicjalizacja wag i biasu dla każdego neuronu w danej warstwie\n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node + 1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "    \n",
    "        # ustawienie liczby neuronów z poprzedniej warstwy na potrzeby następnej iteracji\n",
    "        num_nodes_previous = num_nodes\n",
    "\n",
    "    return network  # zwraca utworzoną sieć\n",
    "\n",
    "\n",
    "def compute_weighted_sum(inputs, weights, bias):\n",
    "    \"\"\"\n",
    "    Funkcja obliczająca sumę ważoną:\n",
    "    mnożymy wejścia przez odpowiadające im wagi, sumujemy i dodajemy bias.\n",
    "    \"\"\"\n",
    "    return np.sum(inputs * weights) + bias\n",
    "\n",
    "\n",
    "def node_activation(weighted_sum):\n",
    "    \"\"\"\n",
    "    Funkcja aktywacji neuronu – wykorzystanie funkcji sigmoid.\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))\n",
    "\n",
    "\n",
    "def forward_propagate(network, inputs):\n",
    "    \"\"\"\n",
    "    Funkcja wykonująca propagację sygnału przez sieć neuronową.\n",
    "    \"\"\"\n",
    "    layer_inputs = list(inputs)  # początkowe wejścia stanowią dane wejściowe sieci\n",
    "    \n",
    "    for layer in network:\n",
    "        layer_data = network[layer]\n",
    "        \n",
    "        layer_outputs = []  # lista wyjść neuronów danej warstwy\n",
    "        for layer_node in layer_data:\n",
    "            node_data = layer_data[layer_node]\n",
    "            \n",
    "            # obliczenie sumy ważonej i funkcji aktywacji dla aktualnego neuronu\n",
    "            node_output = node_activation(compute_weighted_sum(layer_inputs, node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(node_output[0], decimals=4))\n",
    "        \n",
    "        # dla warstw ukrytych wyświetlamy wyniki z neuronów\n",
    "        if layer != 'output':\n",
    "            print('Wyjścia neuronów w warstwie ukrytej numer {} to {}'.format(layer.split('_')[1], layer_outputs))\n",
    "    \n",
    "        # wyjścia z obecnej warstwy stają się wejściami do następnej\n",
    "        layer_inputs = layer_outputs\n",
    "\n",
    "    network_predictions = layer_outputs  # wyjście ostatniej warstwy to wynik sieci\n",
    "    return network_predictions\n",
    "\n",
    "\n",
    "# ----------------- Przykładowe użycie -----------------\n",
    "\n",
    "# Parametry początkowe\n",
    "n = 2  # liczba wejść\n",
    "num_hidden_layers = 2  # liczba warstw ukrytych\n",
    "m = [2, 2]  # liczba neuronów w każdej warstwie ukrytej\n",
    "num_nodes_output = 1  # liczba neuronów w warstwie wyjściowej\n",
    "\n",
    "num_nodes_previous = n  # ustawienie liczby neuronów poprzedniej warstwy na liczbę wejść\n",
    "\n",
    "network = {}  # inicjalizacja pustej sieci\n",
    "\n",
    "# iteracja przez każdą warstwę i losowa inicjalizacja wag oraz biasów dla każdego neuronu\n",
    "# uwzględniamy dodatkową iterację dla warstwy wyjściowej\n",
    "for layer in range(num_hidden_layers + 1):\n",
    "    \n",
    "    # określenie nazwy warstwy\n",
    "    if layer == num_hidden_layers:\n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output\n",
    "    else:\n",
    "        layer_name = 'layer_{}'.format(layer + 1)\n",
    "        num_nodes = m[layer]\n",
    "    \n",
    "    # inicjalizacja wag i biasów dla neuronów w bieżącej warstwie\n",
    "    network[layer_name] = {}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node + 1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "        }\n",
    "    \n",
    "    num_nodes_previous = num_nodes  # aktualizacja liczby neuronów poprzedniej warstwy\n",
    "    \n",
    "print(network)  # wypisanie struktury sieci\n",
    "\n",
    "# Inicjalizacja mniejszej sieci\n",
    "small_network = initialize_network(5, 3, [3, 2, 3], 1)\n",
    "\n",
    "# ----------------- Obliczenia wewnątrz sieci -----------------\n",
    "\n",
    "# Ustawienie seed, aby wyniki były powtarzalne\n",
    "np.random.seed(12)\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
    "\n",
    "print('Wejścia do sieci to {}'.format(inputs))\n",
    "\n",
    "# pobranie wag i biasu dla pierwszego neuronu pierwszej warstwy ukrytej\n",
    "node_weights = small_network['layer_1']['node_1']['weights']\n",
    "node_bias = small_network['layer_1']['node_1']['bias']\n",
    "\n",
    "# obliczenie sumy ważonej dla wybranego neuronu\n",
    "weighted_sum = compute_weighted_sum(inputs, node_weights, node_bias)\n",
    "print('Suma ważona dla pierwszego neuronu w warstwie ukrytej wynosi {}'.format(np.around(weighted_sum[0], decimals=4)))\n",
    "\n",
    "# obliczenie wyniku aktywacji dla wybranego neuronu\n",
    "node_output = node_activation(compute_weighted_sum(inputs, node_weights, node_bias))\n",
    "print('Wynik aktywacji pierwszego neuronu w warstwie ukrytej wynosi {}'.format(np.around(node_output[0], decimals=4)))\n",
    "\n",
    "# ----------------- Propagacja sygnału -----------------\n",
    "\n",
    "# propagacja danych wejściowych przez całą sieć\n",
    "predictions = forward_propagate(small_network, inputs)\n",
    "print('Sieć przewiduje wartość {}'.format(np.around(predictions[0], decimals=4)))\n",
    "\n",
    "# inicjalizacja kolejnej sieci o innej strukturze\n",
    "my_network = initialize_network(5, 3, [2, 3, 2], 3)\n",
    "\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
    "\n",
    "predictions = forward_propagate(my_network, inputs)\n",
    "print('Sieć przewiduje wartości {}'.format(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eff41cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47 0.04 0.08 0.73 0.64 0.03]\n",
      "[0.3  0.22 0.06]\n",
      "x1 wynosi 0.5 oraz x2 wynosi 0.85\n",
      "Suma ważona wejść przy pierwszym neuronie w warstwie ukrytej wynosi 0.569\n",
      "Suma ważona wejść przy drugim neuronie w warstwie ukrytej wynosi 0.8805\n",
      "Aktywacja pierwszego neuronu w warstwie ukrytej wynosi 0.6385\n",
      "Aktywacja drugiego neuronu w warstwie ukrytej wynosi 0.7069\n",
      "Suma ważona wejść przy neuronie warstwy wyjściowej wynosi 0.4899\n",
      "Wynik sieci dla x1 = 0.5 oraz x2 = 0.85 wynosi 0.6201\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Losowa inicjalizacja wag (budowa wag)\n",
    "weights = np.around(np.random.uniform(size=6), decimals=2)\n",
    "# Losowa inicjalizacja biasów (budowa biasów)\n",
    "biases = np.around(np.random.uniform(size=3), decimals=2)\n",
    "\n",
    "print(weights)\n",
    "print(biases)\n",
    "\n",
    "# Deklaracja wejść\n",
    "x_1 = 0.5   # wejście 1\n",
    "x_2 = 0.85  # wejście 2\n",
    "\n",
    "print('x1 wynosi {} oraz x2 wynosi {}'.format(x_1, x_2))\n",
    "\n",
    "# Obliczenie sumy ważonej dla pierwszego neuronu w warstwie ukrytej (budowa sygnału wejściowego)\n",
    "z_11 = x_1 * weights[0] + x_2 * weights[1] + biases[0]\n",
    "print('Suma ważona wejść przy pierwszym neuronie w warstwie ukrytej wynosi {}'.format(z_11))\n",
    "\n",
    "# Obliczenie sumy ważonej dla drugiego neuronu w warstwie ukrytej (budowa sygnału wejściowego)\n",
    "z_12 = x_1 * weights[2] + x_2 * weights[3] + biases[1]\n",
    "print('Suma ważona wejść przy drugim neuronie w warstwie ukrytej wynosi {}'.format(np.around(z_12, decimals=4)))\n",
    "\n",
    "# Obliczenie aktywacji pierwszego neuronu w warstwie ukrytej (budowa aktywacji)\n",
    "a_11 = 1.0 / (1.0 + np.exp(-z_11))\n",
    "print('Aktywacja pierwszego neuronu w warstwie ukrytej wynosi {}'.format(np.around(a_11, decimals=4)))\n",
    "\n",
    "# Obliczenie aktywacji drugiego neuronu w warstwie ukrytej (budowa aktywacji)\n",
    "a_12 = 1.0 / (1.0 + np.exp(-z_12))\n",
    "print('Aktywacja drugiego neuronu w warstwie ukrytej wynosi {}'.format(np.around(a_12, decimals=4)))\n",
    "\n",
    "# Obliczenie sumy ważonej dla neuronu w warstwie wyjściowej (budowa sumy ważonej na wyjściu)\n",
    "z_2 = a_11 * weights[4] + a_12 * weights[5] + biases[2]\n",
    "print('Suma ważona wejść przy neuronie warstwy wyjściowej wynosi {}'.format(np.around(z_2, decimals=4)))\n",
    "\n",
    "# Obliczenie końcowej aktywacji (budowa wyjścia sieci)\n",
    "a_2 = 1.0 / (1.0 + np.exp(-z_2))\n",
    "print('Wynik sieci dla x1 = 0.5 oraz x2 = 0.85 wynosi {}'.format(np.around(a_2, decimals=4)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
